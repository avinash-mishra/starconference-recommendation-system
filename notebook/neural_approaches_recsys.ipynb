{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nafre](../data/books_dataset/images/nafre.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Myself\n",
    "\n",
    "<img src=\"https://media.licdn.com/dms/image/C5103AQFTTkPNQerCIA/profile-displayphoto-shrink_200_200/0?e=1559174400&v=beta&t=e46jBak0gH9thREsq94CitbkQxvqVUrNXFAe3WIuBBE\" width=\"140\" height=\"140\" border-radius=\"50%\" align=\"left\"/>\n",
    "\n",
    "        Avinash Mishra (Avi) | Data Scientist | Catalina marketing Japan\n",
    "\n",
    "        Linkedin : https://www.linkedin.com/in/avinash-mishra-a0846360/\n",
    "  \n",
    "        Github : https://github.com/avinash-mishra\n",
    "\n",
    "        Catalina Japan : https://catalina-jp.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    " - Brief Introduction of recSys\n",
    " - Dataset\n",
    " - Build Models using neural approaches\n",
    " - Embedding visualization\n",
    " - Book recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommendataion Engines are one of the most popular applications of Machine learning systems. Due to their widespread success, they are quickly becoming ubiquitous to a lot of business units. \n",
    "\n",
    "Types of Recommendation Systems:\n",
    "- Popularity based\n",
    "- Content based\n",
    "- Collaborative filtering\n",
    "\t- Nearest Neighbor\n",
    "\t- Matrix Factorization\n",
    "\n",
    "Above methods are quite common to build recommendation systems. \n",
    "\n",
    "In the past couple of years this trend has been changing. Due to the massive success of effectively training deep neural networks, new approaches have been developed by levaraging the tools and modeling flexibility from the Deep Learning ecosystem. \n",
    "\n",
    "This notebook gives a quickstart concepts using neural network architectures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building book Recommendation\n",
    "Goal : <font color=blue>predict the rating or preference a user would give to a book given his old books ratings or preferences. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset : [goodbooks-10k](http://fastml.com/goodbooks-10k-a-new-dataset-for-book-recommendations/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Keras\n",
    "from keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate, Dropout, multiply, concatenate\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import SVG\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv('../data/books_dataset/ratings.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 ratings\n",
    "ratings_df.rating.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total user\n",
    "n_users = ratings_df.user_id.nunique()\n",
    "n_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total books\n",
    "n_books = ratings_df.book_id.nunique()\n",
    "n_books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train & test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(ratings_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(train.head())\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dot product model\n",
    "Most recommendation systems are build using a simple dot product as shown below but newer ones are now implementing a neural network instead of the simple dot product.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras functional api working\n",
    "> Create layers\n",
    "\n",
    "> Combine everything inside model\n",
    "\n",
    "> Compile model\n",
    "\n",
    "> fit the model\n",
    "\n",
    "#### Keras Dot product api is like this\n",
    "`Dot(name=\"Dot-Product\", axes=1)([book_vec, user_vec])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating book embedding path\n",
    "book_input = Input(shape=[1], name=\"Book-Input\")\n",
    "book_embedding = Embedding(n_books+1, output_dim=5, name=\"Book-Embedding\")(book_input)\n",
    "book_vec = Flatten(name=\"Flatten-Books\")(book_embedding)\n",
    "\n",
    "# creating user embedding path\n",
    "user_input = Input(shape=[1], name=\"User-Input\")\n",
    "user_embedding = Embedding(n_users+1, output_dim=5, name=\"User-Embedding\")(user_input)\n",
    "user_vec = Flatten(name=\"Flatten-Users\")(user_embedding)\n",
    "\n",
    "# performing dot product and creating model\n",
    "prod = Dot(name=\"Dot-Product\", axes=1)([book_vec, user_vec])\n",
    "model = Model([user_input, book_input], prod)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model visualization\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save(model, model_name):\n",
    "    epoch = 5\n",
    "    if os.path.exists(f'../models/{model_name}'):\n",
    "        model = load_model(f'../models/{model_name}')\n",
    "    else:\n",
    "        history = model.fit([train.user_id, train.book_id], train.rating, epochs=epoch, verbose=1)\n",
    "        model.save(f'../models/{model_name}')\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Training Error\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_and_save(model, 'dot_product.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "display(['mse, mae'])\n",
    "display(model.evaluate([test.user_id, test.book_id], test.rating))\n",
    "\n",
    "\n",
    "# make prediction\n",
    "predictions = model.predict([test.user_id.head(10), test.book_id.head(10)])\n",
    "\n",
    "print('predicted', 'actual')\n",
    "[print(predictions[i], test.rating.iloc[i]) for i in range(0, 10)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Neural Network\n",
    "\n",
    "Neural Networks proved their effectiveness for almost every machine learning problems with enough data. Neurals Networks perform exceptionally well for recommendation systems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 \n",
    "Use Embedding multiplication and Fully connected Dense NN layer. So that model can learn complex non-linear relationship.\n",
    "\n",
    "<img src=\"../data/books_dataset/images/model1.png\" alt=\"Model 1\" style=\"width: 500px;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating book embedding path\n",
    "book_input = Input(shape=[1], name=\"Book-Input\")\n",
    "book_embedding = Embedding(n_books+1, output_dim=5, name=\"Book-Embedding\")(book_input)\n",
    "\n",
    "# creating user embedding path\n",
    "user_input = Input(shape=[1], name=\"User-Input\")\n",
    "user_embedding = Embedding(n_users+1, output_dim=5, name=\"User-Embedding\")(user_input)\n",
    "\n",
    "# Combine features\n",
    "o = multiply([book_embedding, user_embedding])\n",
    "o = Dropout(0.5)(o)\n",
    "o = Flatten(name=\"Flatten-Embeddings\")(o)\n",
    "\n",
    "# add fully-connected-layers\n",
    "out = Dense(1)(o)\n",
    "\n",
    "# Create model and compile it\n",
    "model1 = Model([user_input, book_input], out)\n",
    "model1.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model visualization\n",
    "SVG(model_to_dot(model1, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = train_and_save(model1, 'model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "display(['mse, mae'])\n",
    "display(f'Dot_product : {[1.1797639321064701, 0.7913027472862053]}')\n",
    "print('model 1')\n",
    "display(model1.evaluate([test.user_id, test.book_id], test.rating))\n",
    "\n",
    "\n",
    "# make prediction\n",
    "predictions = model1.predict([test.user_id.head(10), test.book_id.head(10)])\n",
    "print('predicted', 'actual')\n",
    "[print(predictions[i], test.rating.iloc[i]) for i in range(0, 10)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 \n",
    "Add bias that a user might have in giving consistently high scores to every book he read or a book having consistently bad scores for all users.\n",
    "\n",
    "<img src=\"../data/books_dataset/images/model2.png\" alt=\"Model 2\" style=\"width: 500px;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = 1\n",
    "\n",
    "# creating book embedding path\n",
    "book_input = Input(shape=[1], name=\"Book-Input\")\n",
    "book_embedding = Embedding(n_books+1, output_dim=5, name=\"Book-Embedding\")(book_input)\n",
    "book_bias = Embedding(n_books+1, bias, name=\"Book-Bias-Embedding\")(book_input)\n",
    "\n",
    "# creating user embedding path\n",
    "user_input = Input(shape=[1], name=\"User-Input\")\n",
    "user_embedding = Embedding(n_users+1, output_dim=5, name=\"User-Embedding\")(user_input)\n",
    "user_bias = Embedding(n_users+1, bias, name=\"User-Bias-Embedding\")(user_input)\n",
    "\n",
    "# Combine features\n",
    "o = multiply([book_embedding, user_embedding])\n",
    "o = concatenate([o, book_bias, user_bias])\n",
    "o = Dropout(0.5)(o)\n",
    "o = Flatten(name=\"Flatten-Features\")(o)\n",
    "\n",
    "# add fully-connected-layers\n",
    "out = Dense(1)(o)\n",
    "\n",
    "# Create model and compile it\n",
    "model2 = Model([user_input, book_input], out)\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model visualization\n",
    "SVG(model_to_dot(model2, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = train_and_save(model2, 'model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "display(['mse, mae'])\n",
    "display(f'Dot_product : {[1.1797639321064701, 0.7913027472862053]}')\n",
    "display(f'Model 1 : {[0.8265591262168259, 0.7198698723681436]}')\n",
    "print('model 2')\n",
    "display(model2.evaluate([test.user_id, test.book_id], test.rating))\n",
    "\n",
    "\n",
    "# make prediction\n",
    "predictions = model2.predict([test.user_id.head(10), test.book_id.head(10)])\n",
    "print('predicted', 'actual')\n",
    "[print(predictions[i], test.rating.iloc[i]) for i in range(0, 10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 \n",
    "Add `relu` activation function. The nicest thing about relu is that it’s gradient is always equal to 1, this way we can pass the maximum amount of the error through the network during back-propagation.\n",
    "\n",
    "<img src=\"../data/books_dataset/images/model3.png\" alt=\"Model 3\" style=\"width: 500px;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = 1\n",
    "\n",
    "# creating book embedding path\n",
    "book_input = Input(shape=[1], name=\"Book-Input\")\n",
    "book_embedding = Embedding(n_books+1, output_dim=5, name=\"Book-Embedding\")(book_input)\n",
    "book_bias = Embedding(n_books+1, bias, name=\"Book-Bias-Embedding\")(book_input)\n",
    "\n",
    "# creating user embedding path\n",
    "user_input = Input(shape=[1], name=\"User-Input\")\n",
    "user_embedding = Embedding(n_users+1, output_dim=5, name=\"User-Embedding\")(user_input)\n",
    "user_bias = Embedding(n_users+1, bias, name=\"User-Bias-Embedding\")(user_input)\n",
    "\n",
    "# Combine features\n",
    "o = multiply([book_embedding, user_embedding])\n",
    "o = concatenate([o, book_bias, user_bias])\n",
    "o = Dropout(0.5)(o)\n",
    "o = Flatten(name=\"Flatten-Features\")(o)\n",
    "\n",
    "# add fully-connected-layers\n",
    "o = Dense(10, activation='relu')(o)\n",
    "out = Dense(1, activation='relu')(o)\n",
    "\n",
    "# Create model and compile it\n",
    "model3 = Model([user_input, book_input], out)\n",
    "model3.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model visualization\n",
    "SVG(model_to_dot(model3, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = train_and_save(model3, 'model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "display(['mse, mae'])\n",
    "display(f'Dot_product : {[1.1797639321064701, 0.7913027472862053]}')\n",
    "display(f'Model 1 : {[0.8265591262168259, 0.7198698723681436]}')\n",
    "display(f'Model 2 : {[0.8215828870157219, 0.7241504425097942]}')\n",
    "\n",
    "print('model 3')\n",
    "display(model3.evaluate([test.user_id, test.book_id], test.rating))\n",
    "\n",
    "\n",
    "# make prediction\n",
    "predictions = model3.predict([test.user_id.head(10), test.book_id.head(10)])\n",
    "print('predicted', 'actual')\n",
    "[print(predictions[i], test.rating.iloc[i]) for i in range(0, 10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4 \n",
    "Increase Dense layers to check if model improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = 1\n",
    "\n",
    "# creating book embedding path\n",
    "book_input = Input(shape=[1], name=\"Book-Input\")\n",
    "book_embedding = Embedding(n_books+1, output_dim=5, name=\"Book-Embedding\")(book_input)\n",
    "book_bias = Embedding(n_books+1, bias, name=\"Book-Bias-Embedding\")(book_input)\n",
    "\n",
    "# creating user embedding path\n",
    "user_input = Input(shape=[1], name=\"User-Input\")\n",
    "user_embedding = Embedding(n_users+1, output_dim=5, name=\"User-Embedding\")(user_input)\n",
    "user_bias = Embedding(n_users+1, bias, name=\"User-Bias-Embedding\")(user_input)\n",
    "\n",
    "# Combine features\n",
    "o = multiply([book_embedding, user_embedding])\n",
    "o = concatenate([o, book_bias, user_bias])\n",
    "o = Dropout(0.5)(o)\n",
    "o = Flatten(name=\"Flatten-Features\")(o)\n",
    "\n",
    "# add fully-connected-layers\n",
    "o = Dense(128, activation='relu')(o)\n",
    "o = Dropout(0.2)(o)\n",
    "o = Dense(32, activation='relu')(o)\n",
    "o = Dropout(0.2)(o)\n",
    "out = Dense(1, activation='relu')(o)\n",
    "\n",
    "# Create model and compile it\n",
    "model4 = Model([user_input, book_input], out)\n",
    "model4.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model visualization\n",
    "SVG(model_to_dot(model4, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = train_and_save(model4, 'model4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "display(f'Dot_product : {[1.1797639321064701, 0.7913027472862053]}')\n",
    "display(f'Model 1 : {[0.8265591262168259, 0.7198698723681436]}')\n",
    "display(f'Model 2 : {[0.8215828870157219, 0.7241504425097942]}')\n",
    "display(f'Model 3 : {[0.7899722075320518, 0.7070955941659997]}')\n",
    "\n",
    "\n",
    "display(model4.evaluate([test.user_id, test.book_id], test.rating))\n",
    "\n",
    "\n",
    "# make prediction\n",
    "predictions = model4.predict([test.user_id.head(10), test.book_id.head(10)])\n",
    "\n",
    "[print(predictions[i], test.rating.iloc[i]) for i in range(0, 10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using extra information \n",
    "Often, along with the user-interaction data, other information such as user metadata and item metadata is also given. With the above networks, it's trivial to add this metadata to our model. Let's see how."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = Model([user_input, book_input, age_input, book_contextual_input], out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Embeddings\n",
    "Embeddings are weights that are learned to represent some specific variables like books and user in our case and therefore we can not only use them to get good results on our recommendation problem but also to extract inside about our data. \n",
    "\n",
    "__[Tensorflow embedding projector](http://projector.tensorflow.org/)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings\n",
    "book_em = model4.get_layer('Book-Embedding')   # Book-Embedding is same name that we provided to Embedding layer\n",
    "book_em_weights = book_em.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_em_weights[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "\n",
    "pca = PCA(n_components=2)   # We used output_dim=5 so 1 < n_components <=5 \n",
    "pca_result = pca.fit_transform(book_em_weights)\n",
    "sns.scatterplot(x=pca_result[:, 0], y=pca_result[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataset for making recommendations for the first user\n",
    "book_data = ratings_df.book_id.unique()\n",
    "book_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(ratings_df.user_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = np.array([1 for i in range(len(book_data))])\n",
    "user[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model4.predict([user, book_data])\n",
    "\n",
    "predictions = np.array([a[0] for a in predictions])\n",
    "\n",
    "recommended_book_ids = (-predictions).argsort()[:5]  # sort values in decreasing order and return index\n",
    "\n",
    "recommended_book_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print predicted scores\n",
    "predictions[recommended_book_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv('../data/books_dataset/books.csv')\n",
    "books.iloc[:, :10].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books[books['id'].isin(recommended_book_ids)].iloc[:, :10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Youtube recommendation Engine\n",
    "[Paper link](http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf)\n",
    "\n",
    "<img src=\"../data/books_dataset/images/YouTube.png\" alt=\"YouTube RecSys\" style=\"width: 600px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "1. RecSys is a good use case in Data Science domain.\n",
    "2. Dot product is easy to build and first step for Neural network.\n",
    "3. Built 4 Models:\n",
    "\t- Model 1 : Multiply(user_vec, book_vec) + Dense NN layer\n",
    "\t- Model 2 : Added bias inside concatenation layer concatenate([o, book_bias, user_bias])\n",
    "\t- Model 3 : Added 'relu' Activation function inside Dense NN layer. \n",
    "\t- Model 4 : Added more Dense layers to check if perfomance optimizes. \n",
    "4. Embedding visualization\n",
    "5. Book recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credit where it's due\n",
    " - A brilliant [fast.ai](https://course.fast.ai/videos/?lesson=4) course by Jeremy and Rachel. Refer to Lesson 4 for Collaborative Filtering lecture.\n",
    " - Deep learning class. [link](https://m2dsupsdlclass.github.io/lectures-labs/)\n",
    " - Reference: Keras Model guide. [link](http://faroit.com/keras-docs/1.0.4/getting-started/sequential-model-guide/)\n",
    "\n",
    "### For those who'd like to get deeper\n",
    " - Deep Recommender models using PyTorch - [Spotlight](https://github.com/maciejkula/spotlight). The [Keras implementation](https://github.com/maciejkula/triplet_recommendations_keras).\n",
    " - [YouTube Recommendation Engine](http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf) (Combination of techniques)\n",
    " - [RecSys conference 2017 talks](https://towardsdatascience.com/recsys-2017-2d0879351097)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.tenor.com/images/69d1d66198f1aac60ad244f6c004f372/tenor.gif\" alt=\"Thank You\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
